
services:

  # -------------------------------------------------------------
  # Tooling Stack (database)
  # Profile: database
  # -------------------------------------------------------------
  postgres:
    image: postgres:18.1-alpine
    container_name: neotool-postgres
    restart: unless-stopped
    ports: ["5432:5432"]      
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - postgres-internal
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}      
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - database

  # Database initializer - runs on every 'docker compose up', idempotent
  postgres-init:
    image: postgres:18.1-alpine
    container_name: neotool-postgres-init
    volumes:
      - ../postgres/init-databases.sh:/init-databases.sh:ro
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - postgres-internal
    entrypoint: ["/bin/bash", "/init-databases.sh"]
    environment:
      PGHOST: postgres
      PGPORT: 5432
    restart: "no"
    profiles:
      - database

  pgbouncer:
    image: edoburu/pgbouncer:v1.25.1-p0
    container_name: neotool-pgbouncer
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PGHOST: neotool-postgres
      PGPORT: ${POSTGRES_PORT:-5432}  
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    ports: ["6432:6432"]
    volumes:
      - ../pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ../pgbouncer/userlist.txt:/etc/pgbouncer/userlist.txt:ro
    command: ["pgbouncer", "/etc/pgbouncer/pgbouncer.ini"]
    networks:
      - default
      - postgres-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -p 6432 -U $$POSTGRES_USER"]
      interval: 5s
      timeout: 5s
      retries: 30
    profiles:
      - database

  # -------------------------------------------------------------
  # Kafka Stack (KRaft mode - no Zookeeper needed)
  # Profile: kafka
  # -------------------------------------------------------------
  kafka:
    image: apache/kafka:3.7.0
    container_name: neotool-kafka
    restart: unless-stopped
    ports:
    - "9092:9092"  # Internal Docker network
    - "9094:9094"  # External access (host machine)
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 5s
      start_period: 30s
      retries: 5
    profiles:
      - kafka

  # -------------------------------------------------------------
  # API Gateway Stack
  # Profile: gateway
  # -------------------------------------------------------------

  router:
    image: ghcr.io/apollographql/router:v2.7.0
    container_name: neotool-graphql-router
    ports:
      - "4000:4000"
      - "8088:8088"  # Health check port
      - "9091:9090"  # Metrics port (changed to avoid conflict with Prometheus)
    volumes:
      - ../../contracts/graphql/supergraph/supergraph.local.graphql:/dist/supergraph.graphql:ro
      - ../../infra/router/router.local.yaml:/dist/router.yaml:ro
    command: ["--supergraph", "/dist/supergraph.graphql", "--config", "/dist/router.yaml"]
    environment:
      - APOLLO_ROUTER_LISTEN_ADDRESS=0.0.0.0:4000
      - APOLLO_ROUTER_TELEMETRY_METRICS_PROMETHEUS_ENABLED=true
      - APOLLO_ROUTER_TELEMETRY_METRICS_PROMETHEUS_LISTEN=0.0.0.0:9090
      - APOLLO_ROUTER_TELEMETRY_METRICS_PROMETHEUS_PATH=/metrics
    profiles:
      - gateway

  # -------------------------------------------------------------
  # Storage Stack
  # Profile: storage
  # -------------------------------------------------------------

  minio:
    image: minio/minio:latest
    container_name: neotool-minio
    restart: unless-stopped
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Console UI
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    profiles:
      - storage

  # -------------------------------------------------------------
  # Secrets Stack (Vault)
  # Profile: secrets
  # -------------------------------------------------------------
  vault:
    image: hashicorp/vault:1.21.1
    container_name: neotool-vault
    restart: unless-stopped
    ports:
      - "8200:8200"
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-myroot}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
      VAULT_ADDR: http://0.0.0.0:8200
    cap_add:
      - IPC_LOCK
    volumes:
      - vault-data:/vault/data
      - vault-logs:/vault/logs
    command: ["vault", "server", "-dev"]
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - secrets

  # -------------------------------------------------------------
  # Observability Stack
  # Profile: observability
  # -------------------------------------------------------------

  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: neotool-prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --web.enable-lifecycle
    volumes:
      - ../observability/prometheus/prometheus.local.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    profiles:
      - observability

  grafana:
    image: grafana/grafana:11.1.4
    container_name: neotool-grafana
    ports:
      - "3001:3000"
    volumes:
      - ../observability/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../observability/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    profiles:
      - observability

  # PostgreSQL Exporter - monitors database metrics via pgbouncer
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: neotool-postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER:-neotool}:${POSTGRES_PASSWORD:-neotool}@pgbouncer:6432/${POSTGRES_DB:-neotool_db}?sslmode=disable"
    ports:
      - "9187:9187"
    profiles:
      - observability

  # Loki - Log aggregation system
  loki:
    image: grafana/loki:2.9.0
    container_name: neotool-loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ../observability/loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    depends_on:
      - prometheus
    profiles:
      - observability

  # Promtail - Log collection agent
  promtail:
    image: grafana/promtail:2.9.0
    container_name: neotool-promtail
    volumes:
      - ../observability/promtail/promtail-config.yaml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    profiles:
      - observability

  # -------------------------------------------------------------
  # Feature Flags Stack (Unleash)
  # Profile: feature-flags
  # -------------------------------------------------------------
  unleash:
    image: unleashorg/unleash-server:latest
    container_name: neotool-unleash
    restart: unless-stopped
    environment:
      # Database configuration (via PgBouncer)
      DATABASE_URL: postgres://${UNLEASH_USER:-neotool}:${UNLEASH_PASSWORD:-neotool}@pgbouncer:6432/${UNLEASH_DB:-unleash_db}?sslmode=disable
      DATABASE_HOST: pgbouncer
      DATABASE_PORT: 6432
      DATABASE_NAME: ${UNLEASH_DB:-unleash_db}
      DATABASE_USER: ${UNLEASH_USER:-neotool}
      DATABASE_PASSWORD: ${UNLEASH_PASSWORD:-neotool}
      # Server configuration
      UNLEASH_URL: http://localhost:4242
      PORT: 4242
      # Initial admin user (for first-time setup)
      INIT_ADMIN_API_TOKENS: ${UNLEASH_SERVER_API_TOKEN}
      # Enable UI
      UI_ENABLED: "true"
    ports:
      - "4242:4242"
    networks:
      - default
      - postgres-internal
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:4242/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    profiles:
      - feature-flags

  unleash-edge:
    image: unleashorg/unleash-edge:latest
    container_name: neotool-unleash-edge
    restart: unless-stopped
    command:
      - edge
      - --upstream-url=http://unleash:4242
      - --tokens=${UNLEASH_PROXY_CLIENT_TOKEN}
    environment:
      # Edge configuration
      PORT: 3063
      # CORS configuration
      CORS_ORIGIN: "http://localhost:3000"
      CORS_ALLOWED_HEADERS: "Authorization,Content-Type,unleash-appname,unleash-instanceid,unleash-connection-id,unleash-sdk,if-none-match"
      CORS_METHODS: "GET,POST,OPTIONS,HEAD"
    ports:
      - "3063:3063"
    depends_on:
      unleash:
        condition: service_healthy
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3063/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    profiles:
      - feature-flags
      
volumes:
  pgdata:
  loki-data:
  grafana-data:
  kafka-data:
  minio-data:
  vault-data:
  vault-logs:

networks:
  postgres-internal:
    driver: bridge
    internal: false  # Set to true if you want complete isolation (no internet access)

